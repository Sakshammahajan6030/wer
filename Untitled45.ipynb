{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt75INoTq8vZ"
      },
      "outputs": [],
      "source": [
        "#1. What is a parameter?\n",
        "\n",
        "\n",
        "#In Python, a parameter is a variable in the definition of a function. Parameters\n",
        "#are placeholders for the values (or arguments) that you pass into the function when you call it In Python, a parameter\n",
        "#is a variable in the definition of a function. Parameters are placeholders for the values (or arguments) that you pass into the function when you call it"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):  # 'name' is a parameter\n",
        "    print(f\"Hello, {name}!\")\n",
        "\n",
        "greet(\"Alice\")  # 'Alice' is an argument\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyIhFkeCtV1q",
        "outputId": "90766793-dd25-4748-bd6c-a094714a5556"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Alice!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #2. What is correlation?\n",
        " #What does negative correlation mean?\n",
        "\n",
        "#Correlation is a statistical measure that expresses the extent to which two variables\n",
        "#are linearly related. In other words, it indicates how changes in one variable are associated with changes in anotheCorrelation is a statistical\n",
        "#measure that expresses the extent to which two variables are linearly related. In other words, it indicates how changes in one variable are associated with changes in another"
      ],
      "metadata": {
        "id": "IusVKI5GtYdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A negative correlation means that as one variable increases, the other decreases.\n",
        "#The strength of this relationship is measured by the correlation coefficient, which ranges from -1 to 1. A correlation\n",
        "#coefficient close to -1 indicates a strong negative correlation, meaning the variables move in opposite directions consistently."
      ],
      "metadata": {
        "id": "sUSzmVCGuBVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "# Machine learning is a subset of artificial intelligence (AI) that focuses on\n",
        "# the development of algorithms and statistical models that enable computers to\n",
        "# perform tasks without explicit instructions. Instead, these systems learn from\n",
        "# data, identifying patterns and making decisions based on that information."
      ],
      "metadata": {
        "id": "J7-1cRCLunm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data:\n",
        "#Algorithms\n",
        "#Model\n",
        "#Feature Engineering\n",
        "#Training\n",
        "#Evaluation\n",
        "#Hyperparameter Tuning\n",
        "#Deployment\n",
        "#Monitoring and Maintenance:"
      ],
      "metadata": {
        "id": "X8QGKYZBu-wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "\n",
        "#Loss Value: A metric used to measure how well a machine learning model is performing by comparing the predicted values to the actual values.\n",
        "\n",
        "#Training Guidance: During training, the model's parameters are adjusted to minimize the loss value.\n",
        "\n",
        "#Model Evaluation: Low loss value on test data indicates good performance on unseen data.\n",
        "\n",
        "#Overfitting Detection: High loss on validation data compared to training data can indicate overfitting.\n",
        "\n",
        "#Hyperparameter Tuning: Loss values help find the optimal configuration of model parameters."
      ],
      "metadata": {
        "id": "M9j3btCfvcKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. What are continuous and categorical variables?\n",
        "\n",
        "#Continuous Variables\n",
        "#Can take an infinite number of values within a range.\n",
        "\n",
        "#Examples: height, temperature, time.\n",
        "\n",
        "#Categorical Variables\n",
        "#Represent distinct categories or groups.\n",
        "\n",
        "#Can be nominal (no specific order, e.g., gender) or ordinal (ordered, e.g., education level).\n",
        "\n",
        "#In summary:\n",
        "\n",
        "#Continuous: Measurable and infinite values.\n",
        "\n",
        "#Categorical: Finite and distinct categories or groups."
      ],
      "metadata": {
        "id": "DifDlqZUv7w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #6.How do we handle categorical variables in Machine Learning? What are the common techniques?"
      ],
      "metadata": {
        "id": "djOzEoc2wi39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Label Encoding\n",
        "#Each category is assigned a unique integer value. This technique is simple but can introduce ordinal relationships where there are none.\n",
        "\n",
        "\n",
        "\n",
        "#2. One-Hot Encoding\n",
        "#Each category is represented as a binary vector. This approach avoids the ordinal issue but can lead to high-dimensional data if there are many categories.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#3. Ordinal Encoding\n",
        "#Similar to label encoding but useful for ordinal categories where the order matters, like education levels.\n",
        "\n",
        "\n",
        "\n",
        "#4. Frequency Encoding\n",
        "#Categories are replaced with their frequency in the dataset. This can help with categories that have some implicit importance based on their occurrence.\n",
        "\n",
        "\n",
        "#5. Target Encoding\n",
        "#Categories are replaced with the mean of the target variable for each category. This can be particularly useful in cases where certain categories have a strong relationship with the target variable.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#6. Binary Encoding\n",
        "#Combines the benefits of one-hot encoding and label encoding by converting categories into binary digits and then encoding those as separate columns.\n"
      ],
      "metadata": {
        "id": "tGPp8OTswyUT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.What do you mean by training and testing a dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "3_S6ImZPxjs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Dataset\n",
        "\n",
        "#The training dataset is used to train the machine learning model.\n",
        "#This dataset contains a set of input-output pairs where the model learns the relationships between the inputs (features) and the outputs (labels).\n",
        "#The goal is to allow the model to learn patterns, relationships, and underlying structures in the data so it can make accurate predictions."
      ],
      "metadata": {
        "id": "qjn5Z9rYyDEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Dataset\n",
        "\n",
        "#The testing dataset is used to evaluate the performance of the trained model\n",
        "#This dataset is separate from the training dataset and is used to assess how well the model generalizes to new, unseen data.\n",
        "#It helps ensure that the model's learned patterns are not just specific to the training data but are applicable to other data as well."
      ],
      "metadata": {
        "id": "gxwnE3tOyfUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #8.What is sklearn.preprocessing?\n",
        "\n",
        "#sklearn.preprocessing is a module in the Scikit-learn library\n",
        "#(commonly known as sklearn) that provides various functions and classes to preprocess and transform data before using it in machine learning models.\n",
        "#Preprocessing is a crucial step in the data pipeline to ensure that the data is in a suitable format for modeling. Here are some key functionalities provided by sklearn.preprocessing:"
      ],
      "metadata": {
        "id": "ou8xNrBvy1UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. What is a Test set?\n",
        "\n",
        "#Test Set\n",
        "#Purpose: Used to evaluate the performance of a trained machine learning model.\n",
        "\n",
        "#Separation: Must be separate from the training set to ensure unbiased evaluation.\n",
        "\n",
        "#Generalization: Helps determine how well the model performs on new, unseen data."
      ],
      "metadata": {
        "id": "ltytequ2zbDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.How do we split data for model fitting (training and testing) in Python?\n",
        "#How do you approach a Machine Learning problem?"
      ],
      "metadata": {
        "id": "J0d94EOp0M5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#You can split your data into training and testing sets using the train_test_split function from Scikit-learn. Here’s a basic example:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#You can split your data into training and testing sets using the train_test_split function from Scikit-learn. Here’s a basic example:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'data' is your dataset and 'target' is your labels\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "#In this example, test_size=0.2 indicates that 20% of the data will be used for testing, and random_state=42 ensures reproducibility of the split.\n",
        "\n",
        "#Approaching a Machine Learning Problem\n",
        "#Define the Problem:\n",
        "\n",
        "#Clearly state the problem and the desired outcome.\n",
        "\n",
        "#Understand the business or research objective.\n",
        "\n",
        "#Collect Data:\n",
        "\n",
        "#Gather relevant data from various sources.\n",
        "\n",
        "#Ensure the data is high-quality and representative of the problem.\n",
        "\n",
        "#Explore and Preprocess Data:\n",
        "\n",
        "#Perform exploratory data analysis (EDA) to understand the data distribution and relationships.\n",
        "\n",
        "#Clean the data (handle missing values, remove duplicates).\n",
        "\n",
        "#Feature engineering (create new features, normalize/scale features).\n",
        "\n",
        "#Select a Model:\n",
        "\n",
        "#Choose appropriate machine learning algorithms based on the problem (classification, regression, clustering).\n",
        "\n",
        "#Consider the complexity and interpretability of the model.\n",
        "\n",
        "#Split Data:\n",
        "\n",
        "#Split the data into training and testing sets to evaluate the model’s performance.\n",
        "\n",
        "#Train the Model:\n",
        "\n",
        "#Use the training set to fit the model.\n",
        "\n",
        "#Optimize model parameters and hyperparameters.\n",
        "\n",
        "#Evaluate the Model:\n",
        "\n",
        "#Use the testing set to evaluate the model’s performance.\n",
        "\n",
        "#Use metrics like accuracy, precision, recall, F1-score, RMSE, etc.\n",
        "\n",
        "#Tune and Improve the Model:\n",
        "\n",
        "#Perform hyperparameter tuning (using techniques like Grid Search, Random Search).\n",
        "\n",
        "#Consider cross-validation to ensure the model generalizes well.\n",
        "\n",
        "#Deploy the Model:\n",
        "\n",
        "#Integrate the model into the production environment.\n",
        "\n",
        "#Monitor its performance and update as needed.\n",
        "\n",
        "#Communicate Results:\n",
        "\n",
        "#Share findings and insights with stakeholders.\n",
        "\n",
        "#Make recommendations based on the model’s predictions.\n",
        "\n",
        "#Define the Problem:\n",
        "\n",
        "#Clearly state the problem and the desired outcome.\n",
        "\n",
        "#Understand the business or research objective.\n",
        "\n",
        "#Collect Data:\n",
        "\n",
        "#Gather relevant data from various sources.\n",
        "\n",
        "#Ensure the data is high-quality and representative of the problem.\n",
        "\n",
        "#Explore and Preprocess Data:\n",
        "\n",
        "#Perform exploratory data analysis (EDA) to understand the data distribution and relationships.\n",
        "\n",
        "#Clean the data (handle missing values, remove duplicates).\n",
        "\n",
        "#Feature engineering (create new features, normalize/scale features).\n",
        "\n",
        "#Select a Model:\n",
        "\n",
        "#Choose appropriate machine learning algorithms based on the problem (classification, regression, clustering).\n",
        "\n",
        "#Consider the complexity and interpretability of the model.\n",
        "\n",
        "#Split Data:\n",
        "\n",
        "#Split the data into training and testing sets to evaluate the model’s performance.\n",
        "\n",
        "#Train the Model:\n",
        "\n",
        "#Use the training set to fit the model.\n",
        "\n",
        "#Optimize model parameters and hyperparameters.\n",
        "\n",
        "#Evaluate the Model:\n",
        "\n",
        "#Use the testing set to evaluate the model’s performance.\n",
        "\n",
        "#Use metrics like accuracy, precision, recall, F1-score, RMSE, etc.\n",
        "\n",
        "#Tune and Improve the Model:\n",
        "\n",
        "#Perform hyperparameter tuning (using techniques like Grid Search, Random Search).\n",
        "\n",
        "#Consider cross-validation to ensure the model generalizes well.\n",
        "\n",
        "#Deploy the Model:\n",
        "\n",
        "#Integrate the model into the production environment.\n",
        "\n",
        "#Monitor its performance and update as needed.\n",
        "\n",
        "#Communicate Results:\n",
        "\n",
        "#Share findings and insights with stakeholders.\n",
        "\n",
        "#Make recommendations based on the model’s predictions."
      ],
      "metadata": {
        "id": "ixg5Hrra0cbx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11.Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "#Understand Data Structure\n",
        "\n",
        "#Detect Outliers\n",
        "\n",
        "#Identify Missing Values\n",
        "\n",
        "#Discover Patterns\n",
        "\n",
        "#Inform Feature Selection\n",
        "\n",
        "#Spot Data Quality Issues\n",
        "\n",
        "#Form Hypotheses\n",
        "\n",
        "#Guide Model Choice"
      ],
      "metadata": {
        "id": "s4A2U2Lo0wjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #12.What is correlation?\n",
        "\n",
        "# Key Points\n",
        "#Positive Correlation: When one variable increases, the other variable also increases. Example: As height increases, weight tends to increase.\n",
        "\n",
        "#Negative Correlation: When one variable increases, the other variable decreases. Example: As the number of hours spent watching TV increases, the number of hours spent exercising decreases.\n",
        "\n",
        "#Zero Correlation: No relationship between the variables. Changes in one do not affect the other.\n",
        "\n",
        "#Correlation Coefficient\n",
        "#The correlation coefficient, usually denoted as\n",
        "#𝑟\n",
        "#, quantifies the strength and direction of the relationship:\n",
        "\n",
        "#+1: Perfect positive correlation.\n",
        "\n",
        "#-1: Perfect negative correlation.\n",
        "\n",
        "#0: No correlation."
      ],
      "metadata": {
        "id": "8szlpd5K1uzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13.What does negative correlation mean?\n",
        "\n",
        "#Negative correlation means that as one variable increases, the other variable decreases.\n",
        "#The relationship is represented by a correlation coefficient that ranges from -1 to 0. Here are key points:\n",
        "\n",
        "#Strong Negative Correlation: Closer to -1. Example: As temperature decreases, heating costs increase.\n",
        "\n",
        "#Weak Negative Correlation: Closer to 0, indicating a less pronounced inverse relationship."
      ],
      "metadata": {
        "id": "JkCt4kA02EJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14.How can you find correlation between variables in Python?\n",
        "\n"
      ],
      "metadata": {
        "id": "ary7Mi5n2oy1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = {'A': [1, 2, 3, 4], 'B': ['X', 'Y', 'X', 'Y'], 'C': [10, 15, 14, 20]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Check data types\n",
        "print(df.dtypes)\n",
        "\n",
        "# Convert categorical data to numeric\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calculate correlation\n",
        "correlation_matrix = numeric_df.corr()\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSZcjuN72wfL",
        "outputId": "a4a8007a-77bd-4b9c-bc5c-2ee47c8bb040"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A     int64\n",
            "B    object\n",
            "C     int64\n",
            "dtype: object\n",
            "          A         C\n",
            "A  1.000000  0.910259\n",
            "C  0.910259  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPtfeOIX3BOd",
        "outputId": "83194936-9724-4572-a0d1-cca6370a7ab0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            A         C       B_Y\n",
            "A    1.000000  0.910259  0.447214\n",
            "C    0.910259  1.000000  0.772049\n",
            "B_Y  0.447214  0.772049  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15.What is causation? Explain difference between correlation and causation with an example\n",
        "\n",
        "\n",
        "#Difference Between Correlation and Causation\n",
        "#Correlation: Measures the strength and direction of a relationship between two variables, but does not imply that one variable causes the other to change.\n",
        "\n",
        "#Causation: Implies that one variable directly affects another"
      ],
      "metadata": {
        "id": "OxRKKLi93FqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation: There is a positive correlation between ice cream sales and drowning incidents.\n",
        "#When ice cream sales go up, drowning incidents also tend to increase. However, this does not mean that eating ice cream causes drowning.\n",
        "\n",
        "\n",
        "\n",
        "#Causation: The real causative factor here is the temperature. Higher temperatures lead to both increased ice cream sales and more people swimming,\n",
        "#which can result in more drowning incidents. Thus, while there is a correlation between ice cream sales and drowning incidents, the causation is actually due to the temperature."
      ],
      "metadata": {
        "id": "lfUSP-E3316h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "#An optimizer in the context of machine learning and deep learning is an algorithm or method used to adjust the parameters of a model\n",
        "#(like weights in a neural network) to minimize the loss function and improve the model’s performance."
      ],
      "metadata": {
        "id": "ice_RHit4RB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic gradient descent update rule\n",
        "\n",
        "# Define num_iterations\n",
        "num_iterations = 1000\n",
        "learning_rate = 0.01  # Example learning rate\n",
        "weights = 0  # Example initial weight\n",
        "gradient = 0.5  # Example gradient value, normally calculated in each iteration\n",
        "\n",
        "for i in range(num_iterations):\n",
        "    weights = weights - learning_rate * gradient\n",
        "\n",
        "print(\"Final weights:\", weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWTZoK256q9I",
        "outputId": "db63215f-8d1c-41ad-e478-d18a52ec7a93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final weights: -4.999999999999916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=8, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model with SGD optimizer\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "print(\"Model compiled successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie824bjA60PZ",
        "outputId": "80b5047f-6367-4392-de3f-dcb2684c90c4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model compiled successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {'A': [1, 2, 3, 4], 'B': ['X', 'Y', 'X', 'Y'], 'C': [10, 15, 14, 20]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical data to numeric\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Select only numeric columns\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRngXVGy7XuR",
        "outputId": "a1daec8a-63b0-4092-8592-411cf7ad3912"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            A         C       B_Y\n",
            "A    1.000000  0.910259  0.447214\n",
            "C    0.910259  1.000000  0.772049\n",
            "B_Y  0.447214  0.772049  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "x = np.array([1, 2, 3, 4])\n",
        "y = np.array([10, 11, 12, 13])\n",
        "\n",
        "correlation = np.corrcoef(x, y)[0, 1]\n",
        "print(\"Correlation:\", correlation)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I86DevB7bkV",
        "outputId": "88dc0947-9334-4980-b800-8f0b775027a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Sample data\n",
        "x = [1, 2, 3, 4]\n",
        "y = [10, 11, 12, 13]\n",
        "\n",
        "# Pearson correlation\n",
        "pearson_corr, _ = pearsonr(x, y)\n",
        "print('Pearson correlation: %.3f' % pearson_corr)\n",
        "\n",
        "# Spearman correlation\n",
        "spearman_corr, _ = spearmanr(x, y)\n",
        "print('Spearman correlation: %.3f' % spearman_corr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScSCs3QH7eLh",
        "outputId": "e8e74b0b-431a-4e87-99ea-daaceba84f18"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson correlation: 1.000\n",
            "Spearman correlation: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {'A': [1, 2, 3, 4], 'B': [10, 11, 12, 13], 'C': [5, 6, 7, 8]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Heatmap of correlation matrix\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "q_QTLR0H79Tq",
        "outputId": "cf4ee4ef-c674-4600-e090-ed3a22b68905"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#17What is sklearn.linear_model\n",
        "\n",
        "\n",
        "#sklearn.linear_model is a module in the Scikit-learn library (commonly known as sklearn) that provides a variety of linear models for regression and classification tasks.\n",
        " #This module includes various algorithms that are based on linear relationships between input variables (features) and output variables (target).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbEQ2gLj7_h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18What does model.fit() do? What arguments must be given\n",
        "\n",
        "\n",
        "#Required Arguments\n",
        "#X (Training Data)\n",
        "\n",
        "#Description: The input data used to train the model. This can be in the form of a NumPy array, DataFrame, or tensor.\n",
        "\n",
        "#Example:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DW3YtCQB8yvz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = [[1, 2], [3, 4], [5, 6]]"
      ],
      "metadata": {
        "id": "0QLwQUBd9A37"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y (Target Labels)\n",
        "\n",
        "y_train = [0, 1, 0]\n"
      ],
      "metadata": {
        "id": "pkOXIQvF9IS4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#epochs\n",
        "\n",
        "#Description: Number of times the training process will run through the entire dataset. Used primarily in neural network training.\n",
        "\n",
        "epochs=100\n"
      ],
      "metadata": {
        "id": "M3glPec69OA8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size\n",
        "\n",
        "#Description: Number of samples per gradient update. Also used primarily in neural network training.\n",
        "\n",
        "#Example:\n",
        "\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "XBtGiJN59hXc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
        "y = np.array([0, 1, 0, 1, 0, 1])\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with validation data\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_val, y_val))\n",
        "\n",
        "print(\"Model trained successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq9sgy2w9rcv",
        "outputId": "28c8efcb-7eb2-4896-ec24-2d4cbfb867e2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 5.4180 - val_accuracy: 0.5000 - val_loss: 2.1692\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 5.3687 - val_accuracy: 0.5000 - val_loss: 2.1512\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 5.3194 - val_accuracy: 0.5000 - val_loss: 2.1333\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 5.2702 - val_accuracy: 0.5000 - val_loss: 2.1154\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5000 - loss: 5.2210 - val_accuracy: 0.5000 - val_loss: 2.0976\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 5.1719 - val_accuracy: 0.5000 - val_loss: 2.0798\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 5.1228 - val_accuracy: 0.5000 - val_loss: 2.0621\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5000 - loss: 5.0738 - val_accuracy: 0.5000 - val_loss: 2.0444\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.5000 - loss: 5.0248 - val_accuracy: 0.5000 - val_loss: 2.0268\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 4.9759 - val_accuracy: 0.5000 - val_loss: 2.0092\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 4.9270 - val_accuracy: 0.5000 - val_loss: 1.9917\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 4.8782 - val_accuracy: 0.5000 - val_loss: 1.9742\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 4.8294 - val_accuracy: 0.5000 - val_loss: 1.9568\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 4.7807 - val_accuracy: 0.5000 - val_loss: 1.9395\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5000 - loss: 4.7320 - val_accuracy: 0.5000 - val_loss: 1.9222\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 4.6834 - val_accuracy: 0.5000 - val_loss: 1.9049\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 4.6348 - val_accuracy: 0.5000 - val_loss: 1.8877\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 4.5863 - val_accuracy: 0.5000 - val_loss: 1.8706\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 4.5378 - val_accuracy: 0.5000 - val_loss: 1.8535\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 4.4894 - val_accuracy: 0.5000 - val_loss: 1.8365\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 4.4410 - val_accuracy: 0.5000 - val_loss: 1.8196\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 4.3927 - val_accuracy: 0.5000 - val_loss: 1.8027\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 4.3445 - val_accuracy: 0.5000 - val_loss: 1.7859\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 4.2963 - val_accuracy: 0.5000 - val_loss: 1.7691\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 4.2482 - val_accuracy: 0.5000 - val_loss: 1.7525\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 4.2001 - val_accuracy: 0.5000 - val_loss: 1.7358\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 4.1521 - val_accuracy: 0.5000 - val_loss: 1.7193\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 4.1042 - val_accuracy: 0.5000 - val_loss: 1.7028\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5000 - loss: 4.0563 - val_accuracy: 0.5000 - val_loss: 1.6864\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 4.0085 - val_accuracy: 0.5000 - val_loss: 1.6701\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 3.9607 - val_accuracy: 0.5000 - val_loss: 1.6538\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 3.9130 - val_accuracy: 0.5000 - val_loss: 1.6376\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 3.8654 - val_accuracy: 0.5000 - val_loss: 1.6215\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 3.8179 - val_accuracy: 0.5000 - val_loss: 1.6054\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 3.7704 - val_accuracy: 0.5000 - val_loss: 1.5895\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5000 - loss: 3.7229 - val_accuracy: 0.5000 - val_loss: 1.5736\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 3.6756 - val_accuracy: 0.5000 - val_loss: 1.5578\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5000 - loss: 3.6283 - val_accuracy: 0.5000 - val_loss: 1.5421\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5000 - loss: 3.5811 - val_accuracy: 0.5000 - val_loss: 1.5264\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5000 - loss: 3.5339 - val_accuracy: 0.5000 - val_loss: 1.5109\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 3.4868 - val_accuracy: 0.5000 - val_loss: 1.4954\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5000 - loss: 3.4398 - val_accuracy: 0.5000 - val_loss: 1.4800\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5000 - loss: 3.3929 - val_accuracy: 0.5000 - val_loss: 1.4647\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5000 - loss: 3.3461 - val_accuracy: 0.5000 - val_loss: 1.4495\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5000 - loss: 3.2993 - val_accuracy: 0.5000 - val_loss: 1.4344\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.5000 - loss: 3.2526 - val_accuracy: 0.5000 - val_loss: 1.4194\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.5000 - loss: 3.2060 - val_accuracy: 0.5000 - val_loss: 1.4045\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5000 - loss: 3.1595 - val_accuracy: 0.5000 - val_loss: 1.3896\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5000 - loss: 3.1131 - val_accuracy: 0.5000 - val_loss: 1.3749\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5000 - loss: 3.0667 - val_accuracy: 0.5000 - val_loss: 1.3603\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 3.0205 - val_accuracy: 0.5000 - val_loss: 1.3457\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5000 - loss: 2.9744 - val_accuracy: 0.5000 - val_loss: 1.3313\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.5000 - loss: 2.9283 - val_accuracy: 0.5000 - val_loss: 1.3170\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5000 - loss: 2.8824 - val_accuracy: 0.5000 - val_loss: 1.3028\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 2.8366 - val_accuracy: 0.5000 - val_loss: 1.2887\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5000 - loss: 2.7908 - val_accuracy: 0.5000 - val_loss: 1.2747\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5000 - loss: 2.7452 - val_accuracy: 0.5000 - val_loss: 1.2608\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5000 - loss: 2.6998 - val_accuracy: 0.5000 - val_loss: 1.2470\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5000 - loss: 2.6544 - val_accuracy: 0.5000 - val_loss: 1.2334\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 2.6092 - val_accuracy: 0.5000 - val_loss: 1.2199\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 2.5641 - val_accuracy: 0.5000 - val_loss: 1.2065\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 2.5192 - val_accuracy: 0.5000 - val_loss: 1.1932\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5000 - loss: 2.4744 - val_accuracy: 0.5000 - val_loss: 1.1800\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 2.4298 - val_accuracy: 0.5000 - val_loss: 1.1670\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 2.3853 - val_accuracy: 0.5000 - val_loss: 1.1541\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5000 - loss: 2.3410 - val_accuracy: 0.5000 - val_loss: 1.1413\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5000 - loss: 2.2969 - val_accuracy: 0.5000 - val_loss: 1.1287\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 2.2530 - val_accuracy: 0.5000 - val_loss: 1.1162\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 2.2093 - val_accuracy: 0.5000 - val_loss: 1.1039\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 2.1659 - val_accuracy: 0.5000 - val_loss: 1.0917\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 2.1226 - val_accuracy: 0.5000 - val_loss: 1.0796\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 2.0796 - val_accuracy: 0.5000 - val_loss: 1.0677\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 2.0368 - val_accuracy: 0.5000 - val_loss: 1.0559\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 1.9943 - val_accuracy: 0.5000 - val_loss: 1.0443\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 1.9521 - val_accuracy: 0.5000 - val_loss: 1.0329\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 1.9102 - val_accuracy: 0.5000 - val_loss: 1.0216\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 1.8686 - val_accuracy: 0.5000 - val_loss: 1.0104\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5000 - loss: 1.8274 - val_accuracy: 0.5000 - val_loss: 0.9995\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 1.7865 - val_accuracy: 0.5000 - val_loss: 0.9887\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 1.7459 - val_accuracy: 0.5000 - val_loss: 0.9780\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 1.7058 - val_accuracy: 0.5000 - val_loss: 0.9676\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 1.6661 - val_accuracy: 0.5000 - val_loss: 0.9573\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 1.6269 - val_accuracy: 0.5000 - val_loss: 0.9472\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 1.5881 - val_accuracy: 0.5000 - val_loss: 0.9373\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 1.5498 - val_accuracy: 0.5000 - val_loss: 0.9276\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 1.5120 - val_accuracy: 0.5000 - val_loss: 0.9180\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 1.4748 - val_accuracy: 0.5000 - val_loss: 0.9086\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 1.4382 - val_accuracy: 0.5000 - val_loss: 0.8995\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 1.4022 - val_accuracy: 0.5000 - val_loss: 0.8905\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 1.3668 - val_accuracy: 0.5000 - val_loss: 0.8817\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 1.3321 - val_accuracy: 0.5000 - val_loss: 0.8731\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 1.2981 - val_accuracy: 0.5000 - val_loss: 0.8648\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 1.2649 - val_accuracy: 0.5000 - val_loss: 0.8566\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5000 - loss: 1.2325 - val_accuracy: 0.5000 - val_loss: 0.8486\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 1.2008 - val_accuracy: 0.5000 - val_loss: 0.8409\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5000 - loss: 1.1701 - val_accuracy: 0.5000 - val_loss: 0.8333\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5000 - loss: 1.1402 - val_accuracy: 0.5000 - val_loss: 0.8260\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 1.1112 - val_accuracy: 0.5000 - val_loss: 0.8188\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 1.0831 - val_accuracy: 0.5000 - val_loss: 0.8119\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 1.0561 - val_accuracy: 0.5000 - val_loss: 0.8052\n",
            "Model trained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Training data\n",
        "X_train = [[1, 2], [3, 4], [5, 6]]\n",
        "y_train = [0, 1, 0]\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Fy2PM08K9_sl",
        "outputId": "fd68cbc1-2ef4-43b5-e387-ba0198e2a322"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19What does model.predict() do? What arguments must be given?\n",
        "\n",
        "#What model.predict() Does\n",
        "#Predictions: It generates predictions based on the input data provided, using the trained model.\n",
        "\n",
        "#Inference: Allows you to apply the model to new data to infer the output (e.g., class labels, regression values)."
      ],
      "metadata": {
        "id": "P87YoTuD-Qic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Required Argument\n",
        "#X (Input Data)\n",
        "\n",
        "#Description: The new data on which you want to make predictions. This can be in the form of a NumPy array, DataFrame, or tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "cK-HX5tx-uH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Sample data for training\n",
        "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "y_train = np.array([0, 1, 0])\n",
        "\n",
        "# Create and train the model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(2,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=1)\n",
        "\n",
        "# New data for predictions (converted to NumPy array)\n",
        "X_new = np.array([[5, 6], [7, 8]])\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYRD-G8Q-yqJ",
        "outputId": "49cdbe53-373a-437f-e022-659f7acefd54"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4583 - loss: 0.9793   \n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7083 - loss: 0.5876 \n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4583 - loss: 0.9892     \n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.4882 \n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4583 - loss: 0.9455     \n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7083 - loss: 0.5767 \n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.4266 \n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.4853 \n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7083 - loss: 0.5704 \n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4583 - loss: 0.9125     \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "Predictions: [[0.12578377]\n",
            " [0.06585985]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Training data\n",
        "X_train = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "y_train = np.array([0, 1, 0])\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# New data for predictions\n",
        "X_new = np.array([[7, 8], [9, 10]])\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRHue6FY-8CX",
        "outputId": "5aa88b6a-3be6-4da7-a287-6380fa94bc94"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0.33333333 0.33333333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20What are continuous and categorical variables?\n",
        "\n",
        "#Continuous Variables\n",
        "#Continuous variables are numerical variables that can take on an infinite number of values within a given range.\n",
        "#These values are often measured and can include any value within a continuum. Examples include:\n",
        "\n",
        "#Height (e.g., 170.5 cm)\n",
        "\n",
        "#Weight (e.g., 68.2 kg)\n",
        "\n",
        "#Temperature (e.g., 25.3°C)\n",
        "\n",
        "#Categorical Variables\n",
        "# Categorical variables represent data that can be divided into distinct groups\n",
        "# or categories. These are often non-numeric and are used to label or classify\n",
        "# data. Examples include:\n",
        "\n",
        "#Gender (e.g., Male, Female)\n",
        "\n",
        "#Color (e.g., Red, Blue, Green)\n",
        "\n",
        "#Type of Animal (e.g., Dog, Cat, Bird)"
      ],
      "metadata": {
        "id": "QBhVOrKg-_oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21What is feature scaling? How does it help in Machine Learning\n",
        "\n",
        "#Feature scaling is a technique used to standardize the range of independent variables (features) in a dataset.\n",
        "#This process ensures that different features contribute equally to the model by bringing them to a similar scale.\n",
        "#There are various methods for feature scaling, including normalization and standardization."
      ],
      "metadata": {
        "id": "EECfkv9M_m1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Improves Convergence: Many optimization algorithms, like gradient descent, converge faster with feature scaling because it helps avoid large swings in weight updates.\n",
        "\n",
        "#Avoids Bias: Algorithms that compute distances (like KNN, SVM) or those that rely on the covariance matrix (like PCA) can be biased if features are on different scales.\n",
        "\n",
        "#Enhances Model Performance: Models perform better and make more accurate predictions when all features contribute equally."
      ],
      "metadata": {
        "id": "-iJ7mwLzAUMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22.How do we perform scaling in Python?\n",
        "\n"
      ],
      "metadata": {
        "id": "SHuUcOVHAjQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Normalized Data:\")\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSPWM28oBK7t",
        "outputId": "a000c5ee-caf1-4af3-df2b-7c3ae96f7da1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Data:\n",
            "[[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Standardized Data:\")\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRMckFY3BL4d",
        "outputId": "d065f38d-29f3-4822-e7f2-dec16f252803"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized Data:\n",
            "[[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Robust Scaled Data:\")\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myx2X4Y8BOfx",
        "outputId": "26e9ba51-3eec-4ace-8eec-e4f17338f577"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robust Scaled Data:\n",
            "[[-1. -1.]\n",
            " [ 0.  0.]\n",
            " [ 1.  1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. What is sklearn.preprocessing?\n"
      ],
      "metadata": {
        "id": "tRh_op-2BQX0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Key Components and Functions\n",
        "#tandardScaler\n",
        "\n",
        "#Description: Standardizes features by removing the mean and scaling to unit variance.\n",
        "\n",
        "#Example:\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "MinMaxScaler\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "1LL0n9yhBgzO",
        "outputId": "7066ef44-4e48-42c4-e494-3c3ddbdc4a0f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.preprocessing._data.MinMaxScaler"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sklearn.preprocessing._data.MinMaxScaler</b><br/>def __init__(feature_range=(0, 1), *, copy=True, clip=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py</a>Transform features by scaling each feature to a given range.\n",
              "\n",
              "This estimator scales and translates each feature individually such\n",
              "that it is in the given range on the training set, e.g. between\n",
              "zero and one.\n",
              "\n",
              "The transformation is given by::\n",
              "\n",
              "    X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
              "    X_scaled = X_std * (max - min) + min\n",
              "\n",
              "where min, max = feature_range.\n",
              "\n",
              "This transformation is often used as an alternative to zero mean,\n",
              "unit variance scaling.\n",
              "\n",
              "`MinMaxScaler` doesn&#x27;t reduce the effect of outliers, but it linearly\n",
              "scales them down into a fixed range, where the largest occurring data point\n",
              "corresponds to the maximum value and the smallest one corresponds to the\n",
              "minimum value. For an example visualization, refer to :ref:`Compare\n",
              "MinMaxScaler with other scalers &lt;plot_all_scaling_minmax_scaler_section&gt;`.\n",
              "\n",
              "Read more in the :ref:`User Guide &lt;preprocessing_scaler&gt;`.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "feature_range : tuple (min, max), default=(0, 1)\n",
              "    Desired range of transformed data.\n",
              "\n",
              "copy : bool, default=True\n",
              "    Set to False to perform inplace row normalization and avoid a\n",
              "    copy (if the input is already a numpy array).\n",
              "\n",
              "clip : bool, default=False\n",
              "    Set to True to clip transformed values of held-out data to\n",
              "    provided `feature range`.\n",
              "\n",
              "    .. versionadded:: 0.24\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "min_ : ndarray of shape (n_features,)\n",
              "    Per feature adjustment for minimum. Equivalent to\n",
              "    ``min - X.min(axis=0) * self.scale_``\n",
              "\n",
              "scale_ : ndarray of shape (n_features,)\n",
              "    Per feature relative scaling of the data. Equivalent to\n",
              "    ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
              "\n",
              "    .. versionadded:: 0.17\n",
              "       *scale_* attribute.\n",
              "\n",
              "data_min_ : ndarray of shape (n_features,)\n",
              "    Per feature minimum seen in the data\n",
              "\n",
              "    .. versionadded:: 0.17\n",
              "       *data_min_*\n",
              "\n",
              "data_max_ : ndarray of shape (n_features,)\n",
              "    Per feature maximum seen in the data\n",
              "\n",
              "    .. versionadded:: 0.17\n",
              "       *data_max_*\n",
              "\n",
              "data_range_ : ndarray of shape (n_features,)\n",
              "    Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
              "\n",
              "    .. versionadded:: 0.17\n",
              "       *data_range_*\n",
              "\n",
              "n_features_in_ : int\n",
              "    Number of features seen during :term:`fit`.\n",
              "\n",
              "    .. versionadded:: 0.24\n",
              "\n",
              "n_samples_seen_ : int\n",
              "    The number of samples processed by the estimator.\n",
              "    It will be reset on new calls to fit, but increments across\n",
              "    ``partial_fit`` calls.\n",
              "\n",
              "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
              "    Names of features seen during :term:`fit`. Defined only when `X`\n",
              "    has feature names that are all strings.\n",
              "\n",
              "    .. versionadded:: 1.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "minmax_scale : Equivalent function without the estimator API.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "NaNs are treated as missing values: disregarded in fit, and maintained in\n",
              "transform.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler\n",
              "&gt;&gt;&gt; data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
              "&gt;&gt;&gt; scaler = MinMaxScaler()\n",
              "&gt;&gt;&gt; print(scaler.fit(data))\n",
              "MinMaxScaler()\n",
              "&gt;&gt;&gt; print(scaler.data_max_)\n",
              "[ 1. 18.]\n",
              "&gt;&gt;&gt; print(scaler.transform(data))\n",
              "[[0.   0.  ]\n",
              " [0.25 0.25]\n",
              " [0.5  0.5 ]\n",
              " [1.   1.  ]]\n",
              "&gt;&gt;&gt; print(scaler.transform([[2, 2]]))\n",
              "[[1.5 0. ]]</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 291);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MinMaxScaler\n",
        "\n",
        "#Description: Scales features to a given range, typically [0, 1].\n",
        "\n",
        "#Example:\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "7wMjdT_eBzPn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24.How do we split data for model fitting (training and testing) in Python\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
        "y = np.array([0, 1, 0, 1, 0, 1])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "\n",
        "print(\"Testing Data:\")\n",
        "print(X_test)\n",
        "print(y_test)\n"
      ],
      "metadata": {
        "id": "-AwcxpbsCVuz",
        "outputId": "b1c89e89-1469-4553-f5c2-9416fe881464",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "[[11 12]\n",
            " [ 5  6]\n",
            " [ 9 10]\n",
            " [ 7  8]]\n",
            "[1 0 0 1]\n",
            "Testing Data:\n",
            "[[1 2]\n",
            " [3 4]]\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Explain data encoding?\n",
        "\n",
        "# Data encoding is a crucial preprocessing step in machine learning and data\n",
        "# science that involves transforming categorical data into a numerical format so\n",
        "# that machine learning algorithms can process it. Categorical data includes\n",
        "# variables that represent labels or categories, and most machine learning\n",
        "# models require numerical input. There are several methods for encoding\n",
        "# categorical data:"
      ],
      "metadata": {
        "id": "NYiHh7UICo1P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}